>python splicenet.py
Using TensorFlow backend.
2019-12-03 12:19:00 {'job_name': 'job.splicenet', 'simulator_job': '', 'test_job': '', 'model_job': '', 'n_motif': 4, 'n_motif_train': -1, 'n_region': 2, 'l_seq': 200, 'l_motif': 6, 'n_mismatch': 2, 'n_exon_train': 1000, 'n_exon_test': 100, 'n_experiment_train': 1000, 'n_experiment_test': 100, 'motif_combination': False, 'use_constraints': False, 'output_activation': 'sigmoid', 'l2_regularizer': 0, 'effect_scale': 700, 'fraction_functional': 1.0, 'optimizer': 'adam', 'n_epoch': 1000, 'batch_size': 100, 'verbose': 1, 'patience': 3, 'infinite_training': False, 'RBP_expr': '', 'shuffle_RBP_expr': False, 'gamma_shape': 4, 'gamma_scale': 0.25, 'n_initialization': 5, 'merge_method': 'maxinfo', 'merge_power': 1.0, 'initialization_mode': 'keras_default', 'group_by': 'experiment', 'remove_non_regulated': False, 'no_plot': False, 'no_motif_logo': False}
2019-12-03 12:19:00 create a new model
2019-12-03 12:19:00 save simulator model
2019-12-03 12:19:00 simulating training and test data using the model
2019-12-03 12:19:00 RBP expression: randomly generated from a gamma distribution
2019-12-03 12:19:00 sequences: randomly generated
2019-12-03 12:19:01 generate training and test data
2019-12-03 12:20:16 train a model, or a model initialized with motifs and / or positional effect from the simulation

Train on 1000000 samples, validate on 10000 samples
Epoch 1/1000
1000000/1000000 [==============================] - 37s 37us/step - loss: 0.0981 - val_loss: 0.1008
Epoch 2/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0900 - val_loss: 0.0981
Epoch 3/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0845 - val_loss: 0.0935
Epoch 4/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0803 - val_loss: 0.0906
Epoch 5/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0744 - val_loss: 0.0817
Epoch 6/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0686 - val_loss: 0.0800
Epoch 7/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0678 - val_loss: 0.0794
Epoch 8/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0676 - val_loss: 0.0790
Epoch 9/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0675 - val_loss: 0.0797
Epoch 10/1000
1000000/1000000 [==============================] - 61s 61us/step - loss: 0.0673 - val_loss: 0.0799
Epoch 11/1000
1000000/1000000 [==============================] - 60s 60us/step - loss: 0.0670 - val_loss: 0.0801

2019-12-03 12:31:41 initialization 1 0.0790399898291 0.565366684485 0.443838125557 0.625
2019-12-03 12:31:41 motif rank [2027  185  633    1]
2019-12-03 12:31:41 motif info [ 0.53001743  0.46516717  0.35150066  0.990214  ]
Train on 1000000 samples, validate on 10000 samples
Epoch 1/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.1014 - val_loss: 0.1060
Epoch 2/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0921 - val_loss: 0.0956
Epoch 3/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0828 - val_loss: 0.0908
Epoch 4/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0788 - val_loss: 0.0855
Epoch 5/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0672 - val_loss: 0.0569
Epoch 6/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0451 - val_loss: 0.0425
Epoch 7/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0363 - val_loss: 0.0318
Epoch 8/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0273 - val_loss: 0.0273
Epoch 9/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0256 - val_loss: 0.0281
Epoch 10/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0254 - val_loss: 0.0275
Epoch 11/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0252 - val_loss: 0.0270
Epoch 12/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0249 - val_loss: 0.0267
Epoch 13/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0245 - val_loss: 0.0256
Epoch 14/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0242 - val_loss: 0.0255
Epoch 15/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0240 - val_loss: 0.0252
Epoch 16/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0235 - val_loss: 0.0247
Epoch 17/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0213 - val_loss: 0.0202
Epoch 18/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0167 - val_loss: 0.0152
Epoch 19/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0128 - val_loss: 0.0127
Epoch 20/1000
1000000/1000000 [==============================] - 64s 64us/step - loss: 0.0121 - val_loss: 0.0130
Epoch 21/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0120 - val_loss: 0.0135
Epoch 22/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0119 - val_loss: 0.0128
2019-12-03 12:56:20 initialization 2 0.0127339220028 0.946542185641 0.922705858033 0.75
2019-12-03 12:56:20 motif rank [   1 3217    1    1]
2019-12-03 12:56:20 motif info [ 0.99991593  0.40646588  0.97774557  0.99837835]
Train on 1000000 samples, validate on 10000 samples
Epoch 1/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.1014 - val_loss: 0.1033
Epoch 2/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0935 - val_loss: 0.1008
Epoch 3/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0900 - val_loss: 0.0978
Epoch 4/1000
1000000/1000000 [==============================] - 64s 64us/step - loss: 0.0855 - val_loss: 0.0953
Epoch 5/1000
1000000/1000000 [==============================] - 65s 65us/step - loss: 0.0824 - val_loss: 0.0958
Epoch 6/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0806 - val_loss: 0.0943
Epoch 7/1000
1000000/1000000 [==============================] - 62s 62us/step - loss: 0.0790 - val_loss: 0.0941
Epoch 8/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0775 - val_loss: 0.0921
Epoch 9/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0761 - val_loss: 0.0887
Epoch 10/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0753 - val_loss: 0.0875
Epoch 11/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0746 - val_loss: 0.0865
Epoch 12/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0741 - val_loss: 0.0858
Epoch 13/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0739 - val_loss: 0.0860
Epoch 14/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0738 - val_loss: 0.0854
Epoch 15/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0737 - val_loss: 0.0866
Epoch 16/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0736 - val_loss: 0.0852
Epoch 17/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0736 - val_loss: 0.0856
Epoch 18/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0735 - val_loss: 0.0856
Epoch 19/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0735 - val_loss: 0.0854
2019-12-03 13:17:15 initialization 3 0.0851645776987 0.514757433705 0.741893852054 0.875
2019-12-03 13:17:15 motif rank [ 62 104 246  16]
2019-12-03 13:17:15 motif info [ 0.72501254  0.47934455  0.51881561  0.73142646]
Train on 1000000 samples, validate on 10000 samples
Epoch 1/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0967 - val_loss: 0.0988
Epoch 2/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0862 - val_loss: 0.0946
Epoch 3/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0818 - val_loss: 0.0927
Epoch 4/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0800 - val_loss: 0.0931
Epoch 5/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0790 - val_loss: 0.0908
Epoch 6/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0783 - val_loss: 0.0891
Epoch 7/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0775 - val_loss: 0.0892
Epoch 8/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0752 - val_loss: 0.0864
Epoch 9/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0720 - val_loss: 0.0816
Epoch 10/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0696 - val_loss: 0.0808
Epoch 11/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0691 - val_loss: 0.0819
Epoch 12/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0687 - val_loss: 0.0812
Epoch 13/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0684 - val_loss: 0.0818
2019-12-03 13:31:57 initialization 4 0.0807716188014 0.555983269045 0.621450916748 1.0
2019-12-03 13:31:57 motif rank [ 161    3    1 3570]
2019-12-03 13:31:57 motif info [ 0.6724053   0.39935109  0.93473827  0.40664177]
Train on 1000000 samples, validate on 10000 samples
Epoch 1/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.1069 - val_loss: 0.1083
Epoch 2/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0930 - val_loss: 0.1010
Epoch 3/1000
1000000/1000000 [==============================] - 66s 66us/step - loss: 0.0873 - val_loss: 0.0993
Epoch 4/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0853 - val_loss: 0.0971
Epoch 5/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0845 - val_loss: 0.0974
Epoch 6/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0842 - val_loss: 0.0975
Epoch 7/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0840 - val_loss: 0.0980
2019-12-03 13:39:50 initialization 5 0.0971497266889 0.410161297543 -0.418011059859 0.25
2019-12-03 13:39:50 motif rank [1838 3062 1758 1721]
2019-12-03 13:39:50 motif info [ 0.53066096  0.46924679  0.25605542  0.76229826]
2019-12-03 13:39:51 merging models                                                                         
Train on 1000000 samples, validate on 10000 samples
Epoch 1/1000
1000000/1000000 [==============================] - 67s 67us/step - loss: 0.0235 - val_loss: 0.0155
Epoch 2/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0145 - val_loss: 0.0140
Epoch 3/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0136 - val_loss: 0.0138
Epoch 4/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0131 - val_loss: 0.0139
Epoch 5/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0130 - val_loss: 0.0142
Epoch 6/1000
1000000/1000000 [==============================] - 68s 68us/step - loss: 0.0130 - val_loss: 0.0140
2019-12-03 13:46:39 evaluation =  0.941105144901 0.935525995594 0.75
2019-12-03 13:46:39 motif rank [   1 1716    1    1]
2019-12-03 13:46:39 motif info [ 0.99992029  0.32829098  0.9911181   0.99986538]

